{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing groq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial for various applications and have numerous benefits. Here are some reasons why they are important:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and analyze large amounts of text data quickly, making them suitable for real-time applications such as chatbots, virtual assistants, and language translation.\n",
      "2. **Improved User Experience**: With fast language models, users can receive instant responses to their queries, enhancing their overall experience and satisfaction. This is particularly important in applications like customer support, where timely responses can make a significant difference.\n",
      "3. **Reduced Latency**: Fast language models can reduce latency, which is the time it takes for a model to respond to a user's input. This is especially critical in applications like speech recognition, where low latency is essential for seamless communication.\n",
      "4. **Increased Throughput**: Fast language models can handle a large volume of requests and process them quickly, making them ideal for high-traffic applications like language translation, sentiment analysis, and text summarization.\n",
      "5. **Cost Savings**: Fast language models can lead to significant cost savings by reducing the computational resources required to process text data. This can result in lower cloud computing costs, reduced energy consumption, and increased scalability.\n",
      "6. **Real-time Analytics**: Fast language models enable real-time analytics, which is essential for applications like sentiment analysis, opinion mining, and trend detection. This allows businesses to make data-driven decisions and respond promptly to changing market conditions.\n",
      "7. **Enhanced Security**: Fast language models can quickly analyze and detect potential security threats, such as phishing attacks, spam, and malware, by identifying suspicious patterns and anomalies in text data.\n",
      "8. **Accessibility**: Fast language models can improve accessibility for people with disabilities, such as those who rely on speech-to-text or text-to-speech systems. Quick processing times can enable seamless communication and enhance the overall user experience.\n",
      "9. **Research and Development**: Fast language models accelerate research and development in various fields, such as natural language processing (NLP), machine learning, and artificial intelligence (AI). They enable researchers to test hypotheses, explore new ideas, and develop innovative applications.\n",
      "10. **Competitive Advantage**: Businesses that adopt fast language models can gain a competitive advantage by providing superior customer experiences, improving operational efficiency, and making data-driven decisions faster than their competitors.\n",
      "\n",
      "Some examples of fast language models include:\n",
      "\n",
      "* Transformers (e.g., BERT, RoBERTa)\n",
      "* Recurrent Neural Networks (RNNs)\n",
      "* Long Short-Term Memory (LSTM) networks\n",
      "* Gradient Boosting Machines (GBMs)\n",
      "\n",
      "To achieve fast language models, researchers and developers employ various techniques, such as:\n",
      "\n",
      "* Model pruning and compression\n",
      "* Quantization and knowledge distillation\n",
      "* Parallel processing and distributed computing\n",
      "* Optimization of hyperparameters and model architectures\n",
      "* Using specialized hardware, such as GPUs and TPUs\n",
      "\n",
      "By leveraging these techniques and fast language models, organizations can unlock the full potential of NLP and AI, driving innovation, efficiency, and growth in various industries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Option 2: Directly setting the API key\n",
    "API_KEY = \"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\"\n",
    "\n",
    "client = Groq(api_key=API_KEY)\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Weekly Task Scheduler!\n",
      "\n",
      "Task 'Fix Car' added successfully!\n",
      "\n",
      "\n",
      "Scheduling tasks using llama-3.3-70b-versatile...\n",
      "\n",
      "Received schedule from the model:\n",
      "\n",
      "To create an intelligent weekly schedule for your task, we need to consider the deadline and the hours required. Given that the deadline for \"Fix Car\" is 2025-02-14 and it requires 4 hours, we'll aim to schedule this task in a way that it's completed before the deadline, assuming a standard full-time schedule allows for work from Monday to Friday.\n",
      "\n",
      "Here's a simple approach to schedule the task \"Fix Car\" into a weekly schedule, ensuring it's completed before the deadline. We will allocate the task across a couple of days to fit within a standard workweek, assuming that other tasks or work commitments might also need time slots.\n",
      "\n",
      "```plain\n",
      "BEGIN:VCALENDAR\n",
      "VERSION:2.0\n",
      "CALSCALE:GREGORIAN\n",
      "METHOD:PUBLISH\n",
      "BEGIN:VEVENT\n",
      "UID:fix-car-task\n",
      "DTSTART:2025-02-10T09:00:00Z\n",
      "DTEND:2025-02-10T11:00:00Z\n",
      "SUMMARY:Fix Car (2 hours)\n",
      "DESCRIPTION:Work on fixing the car\n",
      "END:VEVENT\n",
      "BEGIN:VEVENT\n",
      "UID:fix-car-task-2\n",
      "DTSTART:2025-02-12T09:00:00Z\n",
      "DTEND:2025-02-12T13:00:00Z\n",
      "SUMMARY:Fix Car (4 hours)\n",
      "DESCRIPTION:Complete fixing the car\n",
      "END:VEVENT\n",
      "END:VCALENDAR\n",
      "```\n",
      "\n",
      "This schedule allocates 2 hours on Monday (2025-02-10) and the remaining 2 hours on Wednesday (2025-02-12), ensuring the task is completed well before the deadline of 2025-02-14. This is a basic allocation and can be adjusted based on other commitments, the specific schedule of the person involved, and any dependencies that might affect the task's progression.\n",
      "\n",
      "Please note, the time zone used here is Z (Zulu time zone, equivalent to UTC), and the schedule assumes the person is available during the standard working hours (09:00 to 17:00). Adjust the `DTSTART` and `DTEND` fields to fit the actual time zone and schedule of the person responsible for the task.\n",
      "\n",
      "Schedule saved to schedule.ics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "# Directly setting the API key\n",
    "API_KEY = \"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\"\n",
    "\n",
    "# Create the Groq client using your API key\n",
    "client = Groq(api_key=API_KEY)\n",
    "\n",
    "# Global list to store tasks\n",
    "tasks = []\n",
    "\n",
    "def addTask():\n",
    "    \"\"\"\n",
    "    Prompts the user to add a task with a name, deadline, and hours required.\n",
    "    \"\"\"\n",
    "    task_name = input(\"Enter task name: \")\n",
    "    deadline = input(\"Enter deadline (YYYY-MM-DD): \")\n",
    "    hours = input(\"Enter number of hours required: \")\n",
    "    task = {\n",
    "        \"task_name\": task_name,\n",
    "        \"deadline\": deadline,\n",
    "        \"hours\": hours\n",
    "    }\n",
    "    tasks.append(task)\n",
    "    print(f\"Task '{task_name}' added successfully!\\n\")\n",
    "\n",
    "def query_groqcloud(prompt):\n",
    "    \"\"\"\n",
    "    Sends the given prompt to the Groq API using the Llama model\n",
    "    and returns the response.\n",
    "    \"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "def schedule_tasks(tasks):\n",
    "    \"\"\"\n",
    "    Builds a prompt with the tasks information asking the LLM to schedule them\n",
    "    for the week. The LLM is instructed to return the schedule in .ics format.\n",
    "    \"\"\"\n",
    "    prompt = \"I have the following tasks:\\n\"\n",
    "    for task in tasks:\n",
    "        prompt += (\n",
    "            f\"- Task: {task['task_name']}, Deadline: {task['deadline']}, \"\n",
    "            f\"Hours Required: {task['hours']}\\n\"\n",
    "        )\n",
    "    prompt += (\n",
    "        \"\\nPlease create an intelligent weekly schedule for these tasks. \"\n",
    "        \"Consider each task's deadline and required hours. \"\n",
    "        \"Return the schedule in a properly formatted .ics (iCalendar) format.\"\n",
    "    )\n",
    "    return query_groqcloud(prompt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the Weekly Task Scheduler!\\n\")\n",
    "    \n",
    "    # Loop to add tasks until the user is finished\n",
    "    while True:\n",
    "        addTask()\n",
    "        another = input(\"Do you want to add another task? (yes/no): \").strip().lower()\n",
    "        if another != \"yes\":\n",
    "            break\n",
    "\n",
    "    print(\"\\nScheduling tasks using llama-3.3-70b-versatile...\\n\")\n",
    "    schedule_output = schedule_tasks(tasks)\n",
    "    \n",
    "    # Print the schedule received from the LLM\n",
    "    print(\"Received schedule from the model:\\n\")\n",
    "    print(schedule_output)\n",
    "    \n",
    "    # Save the schedule to an .ics file\n",
    "    with open(\"schedule.ics\", \"w\") as file:\n",
    "        file.write(schedule_output)\n",
    "    print(\"\\nSchedule saved to schedule.ics\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
